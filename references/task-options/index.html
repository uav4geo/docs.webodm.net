<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-references/task-options" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0-rc.0">
<title data-rh="true">Task Options | WebODM Lightning</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docs.webodm.net/img/webodm-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://docs.webodm.net/img/webodm-social-card.jpg"><meta data-rh="true" property="og:url" content="https://docs.webodm.net/references/task-options"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Task Options | WebODM Lightning"><meta data-rh="true" name="description" content="Learn about the task options to improve results."><meta data-rh="true" property="og:description" content="Learn about the task options to improve results."><link data-rh="true" rel="icon" href="https://webodm.net/static/icon.png"><link data-rh="true" rel="canonical" href="https://docs.webodm.net/references/task-options"><link data-rh="true" rel="alternate" href="https://docs.webodm.net/references/task-options" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.webodm.net/references/task-options" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://ME1SJLGD0C-dsn.algolia.net" crossorigin="anonymous"><link rel="search" type="application/opensearchdescription+xml" title="WebODM Lightning" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.f6251867.css">
<script src="/assets/js/runtime~main.d45d326b.js" defer="defer"></script>
<script src="/assets/js/main.8fb18528.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="Lightning" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="Lightning" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><span class="navbar__title text--truncate">WebODM Lightning</span></a></div><div class="navbar__items navbar__items--right"><a href="https://webodm.net/faq" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ<!-- --></a><a href="https://webodm.net/dashboard" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Dashboard<!-- --></a><a href="https://webodm.net/register" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar-button">Create Free Account<!-- --></a><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/">Getting Started</a><button aria-label="Expand sidebar category &#x27;Getting Started&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/how-to/">How To</a><button aria-label="Expand sidebar category &#x27;How To&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/references/">References</a><button aria-label="Collapse sidebar category &#x27;References&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/references/task-options">Task Options<!-- --></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/references/create-successful-maps">Create Successful Maps<!-- --></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/references/"><span itemprop="name">References</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Task Options</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page<!-- --></button></div><div class="theme-doc-markdown markdown"><h1>Task Options</h1>
<!-- --><p>When creating a task, press the <!-- --><strong>Edit</strong> button next to the <!-- --><strong>Options</strong> field:<!-- --></p>
<!-- --><figure><div class="container_iyx7"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAHCAYAAAAxrNxjAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA1UlEQVR4nDWOO0vEUBCF7/9vbW1FkLWwsbHTRgSJuKgpXNRkdxUlibmP3GfuJzfqwDBn4JszR0hl8CHwXznnZV5d33JweMTp+QWbpkFM1qHNhDET2hiU0ngfln34HpFKYZ1DGGPo+h4pFcMo0dYR07w4l04p4b1HaF3AgRgTzjren+rct20uQLAWa+0vWMTH5xePzxu887xVVd7XdQ4pYYvrX27hnKPrel63O5Q2hBDw84zZNoxnJ6yOV1zeVIjyYk5puYoxLmDJGMYB93DP+m7NS7vnBwXmCWDEv55EAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="427"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/accessing_task_options.8c32ff3.640.png" srcset="/assets/ideal-img/accessing_task_options.8c32ff3.640.png 640w,/assets/ideal-img/accessing_task_options.7eb1c9c.1024.png 1024w" width="640" height="427"></noscript></div></div><figcaption class="figcaption__A7e"></figcaption></figure>
<!-- --><figure><div class="container_iyx7 padded_zXJG smooth_udfB"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAICAYAAADA+m62AAAACXBIWXMAAC4jAAAuIwF4pT92AAAAy0lEQVR4nG2PvU7DMBSF/fTMjIiFiRdg7hMwBoUOIFdEKSV2Eit22tgJ9ocSVEtIHOnoDvc790cUr2/I6pP6S2Ps+Mf94HAXz/79gFCqwbozMSX+0xIjRVkijqeGzgwZ9vPMGll9DVd1jahPGusueB+YQuC5KAghbECMcatKK4TWGh8C1o0M611mYJr8BnxfQaUQTaNw45nJ/zZXpZSyM6jUOnHOa/ITy4Lue+THkZdyj5BSYq2l67rNbdtijOFQVTztdtzc3nH/8MgP0c8wqoY6AZYAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="527"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/options_as_shown_in_webodm.c8bf853.640.png" srcset="/assets/ideal-img/options_as_shown_in_webodm.c8bf853.640.png 640w,/assets/ideal-img/options_as_shown_in_webodm.029ceb6.1024.png 1024w" alt="Accessing task options from the cloud interface" width="640" height="527"></noscript></div></div><figcaption class="figcaption__A7e">Accessing task options from the cloud interface</figcaption></figure>
<!-- --><p>In general, it&#x27;s a good idea to begin with the default settings, which usually work well for most datasets, and make adjustments as necessary.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="3d-tiles">3d-tiles<!-- --><a href="#3d-tiles" class="hash-link" aria-label="Direct link to 3d-tiles" title="Direct link to 3d-tiles">​</a></h2>
<!-- --><p><a href="https://www.ogc.org/standard/3dtiles/" target="_blank" rel="noopener noreferrer">3D Tiles</a> are a format specification for visualizing and interacting with 3D geospatial content. You can view these files using software like <!-- --><a href="https://github.com/CesiumGS/cesium" target="_blank" rel="noopener noreferrer">Cesium</a>. WebODM Lightning can generate point clouds and textured 3D models in 3D Tiles format. Turn on this option to generate them.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="auto-boundary">auto-boundary<!-- --><a href="#auto-boundary" class="hash-link" aria-label="Direct link to auto-boundary" title="Direct link to auto-boundary">​</a></h2>
<!-- --><p>Automatically calculates a 2D polygon that encloses the camera pose locations. This polygon is subsequently employed as an input for the <!-- --><a href="#boundary">boundary</a> option. The polygon is generated using a convex hull and it&#x27;s adjusted with a distance buffer that scales with the flight altitude, with higher altitudes leading to larger buffers.<!-- --></p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAAC4jAAAuIwF4pT92AAAAUUlEQVR4nFWKsQkAIRDA3H8Rl7BzAq0OKxeQQ1CwECMKwn8gVWLWWhxSSjjnEBF675RSaK3ddjBvDCFgrSXGiKpSa+W135hzxnvPGIM55/XLBg6CcbB/3jGXAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="201"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/auto_boundary.016d390.640.png" srcset="/assets/ideal-img/auto_boundary.016d390.640.png 640w,/assets/ideal-img/auto_boundary.5762f42.1024.png 1024w" alt="Boundary computed from camera poses (dots)" width="640" height="201"></noscript></div></div><figcaption class="figcaption__A7e">Boundary computed from camera poses (dots)</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="auto-boundary-distance">auto-boundary-distance<!-- --><a href="#auto-boundary-distance" class="hash-link" aria-label="Direct link to auto-boundary-distance" title="Direct link to auto-boundary-distance">​</a></h2>
<!-- --><p>Manually adjust the distance buffer value (in meters) for <!-- --><a href="#auto-boundary">auto-boundary</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bg-removal">bg-removal<!-- --><a href="#bg-removal" class="hash-link" aria-label="Direct link to bg-removal" title="Direct link to bg-removal">​</a></h2>
<!-- --><p>Utilizes artificial intelligence techniques to automatically create <!-- --><a href="/how-to/image-masks">image masks</a> for background removal. This is particularly valuable for generating 3D models of individual objects. However, it may not work well in aerial scenes.<!-- --></p>
<!-- --><p>See also <!-- --><a href="#sky-removal">sky-removal</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="boundary">boundary<!-- --><a href="#boundary" class="hash-link" aria-label="Direct link to boundary" title="Direct link to boundary">​</a></h2>
<!-- --><p>Specify a single polygon boundary in GeoJSON format, which is used to define the reconstruction area.</p>
<!-- --><p>GeoJSON polygons can be created using software like QGIS or online tools like <!-- --><a href="https://geojson.io" target="_blank" rel="noopener noreferrer">geojson.io</a>. Additionally, you can automatically generate them using the <!-- --><a href="#auto-boundary">auto-boundary</a> option.<!-- --></p>
<!-- --><p>If the <!-- --><a href="#crop">crop</a> option is set to zero, the boundary polygon can also serve as the crop area for DEMs and orthophotos.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="camera-lens">camera-lens<!-- --><a href="#camera-lens" class="hash-link" aria-label="Direct link to camera-lens" title="Direct link to camera-lens">​</a></h2>
<!-- --><p>Digital camera sensors quantify the incoming light. Prior to reaching the sensor, light traverses through a camera lens. Lenses introduce different degrees of distortion into photos, with the specific type of distortion determined by the lens shape. This distortion can range from pronounced, such as in fisheye or wide-angle lenses, to more subtle in the case of perspective lenses. It&#x27;s essential to recognize that some level of distortion is invariably present.</p>
<!-- --><p>WebODM Lightning offers support for multiple lens models and automatically selects the most suitable one by considering the information available in the EXIF<!-- --><sup><a href="#user-content-fn-exif" id="user-content-fnref-exif" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup> and XMP<!-- --><sup><a href="#user-content-fn-xmp" id="user-content-fnref-xmp" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup> tags of the images. Nevertheless, there are instances where such information is absent. In these cases, if you encounter difficulties when processing images captured with a fisheye lens, it&#x27;s advisable to manually designate either <!-- --><code>fisheye</code> or <!-- --><code>fisheye_opencv</code> as the camera-lens option. As a general guideline, when your input images exhibit noticeable distortion, it&#x27;s a prudent approach to manually configure this option with the appropriate value.<!-- --></p>
<!-- --><table><thead><tr><th><strong>Value</strong></th><th><strong>Images</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td><strong>auto</strong></td><td>Normal</td><td>Defaults to <!-- --><strong>brown</strong>, unless the XMP tag <!-- --><code>GPano:ProjectionType</code> or <!-- --><code>Camera:ModelType</code> contains a value from this table<!-- --></td></tr><tr><td><strong>perspective</strong></td><td>Normal</td><td>Handles radial distortion</td></tr><tr><td><strong>brown</strong></td><td>Normal</td><td>Handles radial, tangential, and principal point distortions</td></tr><tr><td><strong>fisheye</strong></td><td>Ultra wide-angle</td><td>Handles radial distortion</td></tr><tr><td><strong>fisheye_opencv</strong></td><td>Ultra wide-angle</td><td>Handles radial distortion, tangential, and principal point distortions</td></tr><tr><td><strong>spherical</strong></td><td>360</td><td>Handles spherical projection for 360 images</td></tr><tr><td><strong>equirectangular</strong></td><td>360</td><td>Same as <!-- --><em>spherical</em> (legacy name)<!-- --></td></tr><tr><td><strong>dual</strong></td><td>Ultra wide-angle / Normal</td><td>Handles radial distortion from sensors that can capture both fisheye and perspective images, transitioning from one to the other.</td></tr></tbody></table>
<!-- --><p>Please be aware that utilizing this option applies the same camera lens model to all images, even if they originate from different cameras. To apply distinct models for different cameras, it&#x27;s necessary to ensure that the images have the appropriate XMP tags set.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="cameras">cameras<!-- --><a href="#cameras" class="hash-link" aria-label="Direct link to cameras" title="Direct link to cameras">​</a></h2>
<!-- --><p>By default WebODM Lightning estimates the camera model&#x27;s distortion parameters from the input images. This option allows you to choose a precomputed set of parameters instead from another task. You can do this by providing a <!-- --><strong>cameras.json</strong> file, which is generated after processing a dataset and can be downloaded from the cloud interface by clicking <!-- --><strong>Download Assets</strong> → <!-- --><strong>Camera Parameters</strong>. This feature can be helpful in improving the accuracy of certain datasets, especially those that didn&#x27;t follow good image capture guidelines.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="crop">crop<!-- --><a href="#crop" class="hash-link" aria-label="Direct link to crop" title="Direct link to crop">​</a></h2>
<!-- --><p>The crop area for orthophotos and DEMs is calculated from the point cloud, first by defining a convex hull around the points and then shrinking it by <!-- --><code>crop</code> amount (in meters).<!-- --></p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAAC1HAAAtRwHZ/3hdAAAAg0lEQVR4nBXKLwqCMRgH4BfEZPYAmg0ieAGLybsMdgT7DrC8E3xh7F/Z+2OsyT6wWLRosNsnqw8PEdFaKXWx1r6mabp571dERDnnA4AngK+UcjeMmPk6z3Nn5p8xZk9Ei1qrTCn1EEJvrZ3HWwohTs65D4CH1nozMMa4ZeY7gHcp5fgH+B5AwRa0+RIAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="192"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/point_cloud_and_shrinked_bounds.4690649.640.png" srcset="/assets/ideal-img/point_cloud_and_shrinked_bounds.4690649.640.png 640w,/assets/ideal-img/point_cloud_and_shrinked_bounds.9d69fa9.1024.png 1024w" alt="Point cloud (left) and cropped bounds (right)" width="640" height="192"></noscript></div></div><figcaption class="figcaption__A7e">Point cloud (left) and cropped bounds (right)</figcaption></figure>
<!-- --><p>This option can be set to zero to skip cropping.</p>
<!-- --><p>One can also set the <!-- --><a href="#boundary">boundary</a> option and set this option to zero to manually define the crop area.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dem-decimation">dem-decimation<!-- --><a href="#dem-decimation" class="hash-link" aria-label="Direct link to dem-decimation" title="Direct link to dem-decimation">​</a></h2>
<!-- --><p>DEMs are computed from the point cloud. To speed up the process, you can use this option to reduce the number of points used. Setting it to 3 keeps every third point, discarding the rest to speed up computation.</p>
<!-- --><p>The default value of <!-- --><code>1</code> includes all points. Setting it to <!-- --><code>50</code> keeps approximately 2% of the original points and discards around 98%. You can calculate this percentage by:<!-- --></p>
<!-- --><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">decimation </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">50</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> decimation</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># &lt;-- 2%</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dem-euclidean-map">dem-euclidean-map<!-- --><a href="#dem-euclidean-map" class="hash-link" aria-label="Direct link to dem-euclidean-map" title="Direct link to dem-euclidean-map">​</a></h2>
<!-- --><p>An Euclidean map is a georeferenced image created from Digital Elevation Models (DEMs) before filling any gaps. In this image, each pixel represents the geometric distance to the nearest void, null, or NODATA pixel. It serves as a visual indicator of how far a value in the DEM is from an area with no data. This is valuable when you want to distinguish areas in the DEM that are based on actual point cloud values from those filled with interpolation.</p>
<!-- --><p>In the Euclidean map, every pixel with a value of zero indicates that the corresponding location in the DEM was filled using interpolation, as the distance from a NODATA pixel to itself is zero. You can generate this map by turning on this option.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAAD+wAAA/sAFldtx/AAAAeUlEQVR4nD3MsQ3DIBBAUYZIkXU8QSbxFhkhDStQgdKAKCiQ6LggneBwhSy3LOCKyBT+9dNnjDGmlFq11ocxZpNSLs65ByL+EHFPKX0uM7PWvgFglFJGrfUlhHi21s7e+yCi7w1jjKv3/gghbES0cM7nMee8A8A8/gH8rEdrhZWwtwAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="209"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/dem_euclidean_map.9c919a6.640.png" srcset="/assets/ideal-img/dem_euclidean_map.9c919a6.640.png 640w,/assets/ideal-img/dem_euclidean_map.3515974.1024.png 1024w" alt="DEM before hole filling (left) and corresponding euclidean map (right)" width="640" height="209"></noscript></div></div><figcaption class="figcaption__A7e">DEM before hole filling (left) and corresponding euclidean map (right)</figcaption></figure>
<!-- --><p>The resulting map will be available from <!-- --><strong>Download Assets</strong> → <!-- --><strong>All Assets</strong> in the <!-- --><code>odm_dem</code> folder.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dem-gapfill-steps">dem-gapfill-steps<!-- --><a href="#dem-gapfill-steps" class="hash-link" aria-label="Direct link to dem-gapfill-steps" title="Direct link to dem-gapfill-steps">​</a></h2>
<!-- --><p>DEMs are image grids with cells that must have values. Cells can have zero, one, or more points based on the raster&#x27;s resolution. Assigning values to all cells, even those without direct points, is crucial to avoid gaps. To find the right radius, WebODM Lightning computes multiple DEMs with varying radii, stacking results from small radii (more accuracy, more gaps) to large radii (less accuracy, fewer gaps). If gaps persist, it fills them with less accurate interpolation. The number of layers depends on this option.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAAD+wAAA/sAFldtx/AAAAhElEQVR4nGO4ePFi/IWzZyMYGBhYDlVWip5pbc3eUlrqyMDAwHDL0THzuqPjgtPW1g4ML168+Hj16tWHDAwMnDe6u03fzp79/3BNzTyQwuceHsf++fv/P2Vh0c5w7ty55GXLlsUwMDAwHWptFd1TX18wJy0NbOJ1J6f0S/b2Cw6amtoBAIA1NfYVmPJaAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="209"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/dem_gapfill_steps.8588601.640.png" srcset="/assets/ideal-img/dem_gapfill_steps.8588601.640.png 640w,/assets/ideal-img/dem_gapfill_steps.b503622.1024.png 1024w" alt="Pixels and points (left), radius of 0.5 (middle) and radius of 1 (right)" width="640" height="209"></noscript></div></div><figcaption class="figcaption__A7e">Pixels and points (left), radius of 0.5 (middle) and radius of 1 (right)</figcaption></figure>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAECAYAAAC3OK7NAAAACXBIWXMAAD+wAAA/sAFldtx/AAAAcElEQVR4nGNgYGBgZIAApmnTpvUdPXp0spmZGR8DAwM3VBwC/v//D1PIcuzYsRMXL148b2NjI8jAwMBrb2/PgqFw//79LBs3bjy5bNmy87q6uiCFQsbGxqzIhsJMZE5PT2/Kzc1tV1FRAVnNiyTHAAC5hyEXs8gAbAAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="244"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/dem_gapfill_interpolation.f268334.640.png" srcset="/assets/ideal-img/dem_gapfill_interpolation.f268334.640.png 640w,/assets/ideal-img/dem_gapfill_interpolation.c5d5604.1024.png 1024w" alt="Gap fill interpolation with 2 DEM layers" width="640" height="244"></noscript></div></div><figcaption class="figcaption__A7e">Gap fill interpolation with 2 DEM layers</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dem-resolution">dem-resolution<!-- --><a href="#dem-resolution" class="hash-link" aria-label="Direct link to dem-resolution" title="Direct link to dem-resolution">​</a></h2>
<!-- --><p>This option specifies the output resolution of DEMs in cm / pixel.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAAD+wAAA/sAFldtx/AAAAX0lEQVR4nGNggABmBgYGFgYGBkFvb2+X+vp6ozNnzrBC5RBAXFycm4GBQVhMTEzp4cOHd9++ffv/1KlTpiC5////M8EV/v//nxFE19fXs929e3f//fv3nx0/flwPWSEAg14j0VhN1EMAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="209"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/dem_resolution.8d48364.640.png" srcset="/assets/ideal-img/dem_resolution.8d48364.640.png 640w,/assets/ideal-img/dem_resolution.d60f959.1024.png 1024w" alt="Pixels in a raster DEM" width="640" height="209"></noscript></div></div><figcaption class="figcaption__A7e">Pixels in a raster DEM</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dsm">dsm<!-- --><a href="#dsm" class="hash-link" aria-label="Direct link to dsm" title="Direct link to dsm">​</a></h2>
<!-- --><p>This option creates a digital surface model (DSM). DSMs are created by identifying the highest elevation values in a point cloud, which includes terrain and various structures like buildings and trees. When two points coincide, only the tallest point is considered. Any gaps in the point cloud are filled using the method detailed in <!-- --><a href="#dem-gapfill-steps">dem-gapfill-steps</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dtm">dtm<!-- --><a href="#dtm" class="hash-link" aria-label="Direct link to dtm" title="Direct link to dtm">​</a></h2>
<!-- --><p>This option creates a digital terrain model (DTM). DTMs are created by applying a hybrid method that combines a simple morphological filter<!-- --><sup><a href="#user-content-fn-smrf" id="user-content-fnref-smrf" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup> (SMRF) with artificial intelligence. Enabling this option also activates the <!-- --><a href="#pc-classify">pc-classify</a> feature. Non-ground points are removed before DTM calculation. Any gaps in the point cloud are filled using the process explained in <!-- --><a href="#dem-gapfill-steps">dem-gapfill-steps</a>. For additional details refer to the <!-- --><a href="#pc-classify">pc-classify</a> option.<!-- --></p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAACCAYAAABhYU3QAAAACXBIWXMAACqnAAAqpwFRLbg4AAAASElEQVR4nCWKMQrAIBTF0m5W4Vnon7oJ3kJw8twe7ZdPsyUE4ABq7/2dcz7AyU8dY9jeu7h7PFwRJd2tNQEZSOGS6lorm1n5AKZMChB4P1aFAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="149"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/dsm_vs_dtm.8e18349.640.png" srcset="/assets/ideal-img/dsm_vs_dtm.8e18349.640.png 640w,/assets/ideal-img/dsm_vs_dtm.0a8b2b0.1024.png 1024w" alt="DSM (left) vs. DTM (right)" width="640" height="149"></noscript></div></div><figcaption class="figcaption__A7e">DSM (left) vs. DTM (right)</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="end-with">end-with<!-- --><a href="#end-with" class="hash-link" aria-label="Direct link to end-with" title="Direct link to end-with">​</a></h2>
<!-- --><p>Instead of processing the entire photogrammetry pipeline, the pipeline will stop the execution at the chosen step.</p>
<!-- --><table><thead><tr><th>Option</th><th>Stage</th></tr></thead><tbody><tr><td>dataset</td><td>Load Dataset</td></tr><tr><td>split</td><td>Split</td></tr><tr><td>merge</td><td>Merge</td></tr><tr><td>opensfm</td><td>Structure From Motion</td></tr><tr><td>openmvs</td><td>Multi View Stereo</td></tr><tr><td>odm_filterpoints</td><td>Point Filtering</td></tr><tr><td>odm_meshing</td><td>Meshing</td></tr><tr><td>mvs_texturing</td><td>Texturing</td></tr><tr><td>odm_georeferencing</td><td>Georeferencing</td></tr><tr><td>odm_dem</td><td>DEM</td></tr><tr><td>odm_orthophoto</td><td>Orthophoto</td></tr><tr><td>odm_report</td><td>Report</td></tr><tr><td>odm_postprocess</td><td>Postprocess</td></tr></tbody></table>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="fast-orthophoto">fast-orthophoto<!-- --><a href="#fast-orthophoto" class="hash-link" aria-label="Direct link to fast-orthophoto" title="Direct link to fast-orthophoto">​</a></h2>
<!-- --><p>For flat areas (agriculture fields), this option can save some substantial computation time by not requiring the construction of the dense point cloud used for orthorectification. This option does not work well in urban scenes due to excessive relief displacement artifacts.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG smooth_udfB"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAALAAoDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAQMF/8QAIhAAAwABAwMFAAAAAAAAAAAAAQIDBAAREgUhMQYUQVFh/8QAFQEBAQAAAAAAAAAAAAAAAAAAAgT/xAAbEQACAQUAAAAAAAAAAAAAAAAAAQIDEjFR0f/aAAwDAQACEQMRAD8AyrmIhFY4J4tSfLIaZGy9/keSfrTUxWrg+mjQgkc/Z7cv3bT1a1Ev0/HRysaZaBlHggb7apm2rHMvObsqJRlUA+AD21Paot8Wg08H/9k=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="728"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/normal_vs_fastortho.c9f349e.640.jpg" srcset="/assets/ideal-img/normal_vs_fastortho.c9f349e.640.jpg 640w,/assets/ideal-img/normal_vs_fastortho.6237a5f.1024.jpg 1024w" alt="Normal (top) vs. fast-orthophoto (bottom)" width="640" height="728"></noscript></div></div><figcaption class="figcaption__A7e">Normal (top) vs. fast-orthophoto (bottom)</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="feature-quality">feature-quality<!-- --><a href="#feature-quality" class="hash-link" aria-label="Direct link to feature-quality" title="Direct link to feature-quality">​</a></h2>
<!-- --><p>The photogrammetry process starts by identifying points of interest (features) from the input images. To expedite this, extraction is performed on a scaled-down version of the input images, determined by a scaling factor.</p>
<!-- --><table><thead><tr><th><strong>Option</strong></th><th><strong>Factor</strong></th></tr></thead><tbody><tr><td>high</td><td>1/2 (default)</td></tr><tr><td>medium</td><td>1/4</td></tr><tr><td>low</td><td>1/8</td></tr><tr><td>lowest</td><td>1/16</td></tr></tbody></table>
<!-- --><p>For example, choosing <!-- --><strong>medium</strong> uses 1/4 of the original image size. The default value works for most cases, without affecting image sizes or orthophoto resolution. Sometimes, decreasing this value can be helpful in forest areas that lack sufficient overlap.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="feature-type">feature-type<!-- --><a href="#feature-type" class="hash-link" aria-label="Direct link to feature-type" title="Direct link to feature-type">​</a></h2>
<!-- --><p>WebODM Lightning provides multiple algorithms for extracting image features. For the most consistent and reliable results, we recommend using the default <!-- --><strong>dspsift</strong> algorithm. However, in specific scenes or situations, you may benefit from using alternative algorithms. Refer to the table below.<!-- --></p>
<!-- --><table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>sift</td><td>General-purpose, works well in most cases<!-- --><sup><a href="#user-content-fn-sift" id="user-content-fnref-sift" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup></td></tr><tr><td>dspsift</td><td>General-purpose, slower but generally more accurate than sift. Performs better in scenes with low overlap or vegetation<!-- --><sup><a href="#user-content-fn-dspsift" id="user-content-fnref-dspsift" data-footnote-ref="true" aria-describedby="footnote-label">5</a></sup></td></tr><tr><td>akaze</td><td>General-purpose, can perform better on scenes with fewer objects of interest (e.g. forests, vegetation)<!-- --><sup><a href="#user-content-fn-akaze" id="user-content-fnref-akaze" data-footnote-ref="true" aria-describedby="footnote-label">6</a></sup></td></tr><tr><td>hahog</td><td>General-purpose, similar to sift. It&#x27;s the only one that works with <!-- --><a href="#matcher-type">matcher-type</a> bow<!-- --><sup><a href="#user-content-fn-hahog" id="user-content-fnref-hahog" data-footnote-ref="true" aria-describedby="footnote-label">7</a></sup></td></tr><tr><td>orb</td><td>Fast, but does not work well with images that have scale variations (images taken at varying altitudes)<!-- --><sup><a href="#user-content-fn-orb" id="user-content-fnref-orb" data-footnote-ref="true" aria-describedby="footnote-label">8</a></sup></td></tr></tbody></table>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="force-gps">force-gps<!-- --><a href="#force-gps" class="hash-link" aria-label="Direct link to force-gps" title="Direct link to force-gps">​</a></h2>
<!-- --><p>When a GCP file is utilized, the default behavior is to disregard all GPS data, relying solely on the GCP file for georeferencing. The underlying assumption is that GCP data is more accurate than GPS. However, if the GPS data is highly accurate (e.g., with RTK<!-- --><sup><a href="#user-content-fn-rtk" id="user-content-fnref-rtk" data-footnote-ref="true" aria-describedby="footnote-label">9</a></sup> correction), enabling this option directs the program to use both GCP and GPS data for georeferencing.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="gps-accuracy">gps-accuracy<!-- --><a href="#gps-accuracy" class="hash-link" aria-label="Direct link to gps-accuracy" title="Direct link to gps-accuracy">​</a></h2>
<!-- --><p>GPS data has a certain level of accuracy. This value is used to specify how much GPS data should be constrained during the photogrammetry process.</p>
<!-- --><p>Typically, accuracy information is obtainable from XMP tags in the images. WebODM Lightning uses twice the number indicated in any of the following tags (to account for underestimation):</p>
<!-- --><ul>
<!-- --><li><strong>drone-dji::RtkStdLon</strong></li>
<!-- --><li><strong>drone-dji::RtkStdLat</strong></li>
<!-- --><li><strong>drone-dji::RtkStdHgt</strong></li>
<!-- --><li><strong>Camera::GPSXYAccuracy</strong></li>
<!-- --><li><strong>GPSXYAccuracy</strong></li>
<!-- --><li><strong>Camera::GPSZAccuracy</strong></li>
<!-- --><li><strong>GPSZAccuracy</strong></li>
<!-- --></ul>
<!-- --><p>If multiple tags are present, the maximum value is used. If no tags are available, the default is <!-- --><strong>10 meters</strong>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="matcher-neighbors">matcher-neighbors<!-- --><a href="#matcher-neighbors" class="hash-link" aria-label="Direct link to matcher-neighbors" title="Direct link to matcher-neighbors">​</a></h2>
<!-- --><p>During reconstruction image pairs are matched by identifying common features. The brute-force approach compares each image with every other, resulting in exhaustive but slow searching. For a 100-image dataset, it would require numerous comparisons.</p>
<!-- --><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># &lt;-- 9900 comparisons</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- --><p>To enhance efficiency, the program employs optimizations. The concept is that for datasets gathered uniformly, most images are paired with nearby ones. Using GPS data, the program quickly approximates which images are adjacent and excludes distant ones. This process is termed preemptive matching.</p>
<!-- --><p>WebODM Lightning by default applies a graph connectivity approach for preemptive matching. It uses GPS locations to link images with edges through Delaunay triangulation<!-- --><sup><a href="#user-content-fn-delaunay" id="user-content-fnref-delaunay" data-footnote-ref="true" aria-describedby="footnote-label">10</a></sup>. If two images share an edge, they form a pair. To generate more pairs, the method shuffles GPS locations to create multiple graphs (a total of 50). All pairs from these graphs are considered for further matching.<!-- --></p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAAC4jAAAuIwF4pT92AAAAXUlEQVR4nD3MMQ4AEQBE0b3/GXRugcYFnEEjEUFQKBT+hmR32v8yz96bs9YaSilKKYwx0FrjvWetdfvzwZwzUkpijKSUEELgnGPOyTE/PI/GGGqt9N6x1hJCuOjAF6INbuOiP+3lAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="201"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/graph_rounds.27da6b9.640.png" srcset="/assets/ideal-img/graph_rounds.27da6b9.640.png 640w,/assets/ideal-img/graph_rounds.a6eb5b2.1024.png 1024w" alt="Initial graph (left) and graph with randomly moved positions and new edges (right). Each edge represents an image pair" width="640" height="201"></noscript></div></div><figcaption class="figcaption__A7e">Initial graph (left) and graph with randomly moved positions and new edges (right). Each edge represents an image pair</figcaption></figure>
<!-- --><p>WebODM Lightning offers an alternative preemptive matching method that focuses on the nearest neighbors of each image instead of using a graph. You can enable this method by turning on this option:</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAAITvAACE7wFO9C1tAAAAXUlEQVR4nD3MMQ6EIBBA0V86065KWLfxbLQUXIIODjChp+aIBrP665cPQK1VWmuulLL23l0IwQEfVfWATHNnZjrG+IrIEWM8U0oTTPwD9IXPMee8mZn/H1dgB5aJLp9bGL/3j5I9AAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="202"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/matcher_neighbors.f438a64.640.png" srcset="/assets/ideal-img/matcher_neighbors.f438a64.640.png 640w,/assets/ideal-img/matcher_neighbors.5df57b1.1024.png 1024w" alt="Dots represent approximate image locations, extracted from EXIF tags. When matcher-neighbors is set to 8, only the 8 nearest neighbors (highlighted in gray) are considered for matching with image p1" width="640" height="202"></noscript></div></div><figcaption class="figcaption__A7e">Dots represent approximate image locations, extracted from EXIF tags. When matcher-neighbors is set to 8, only the 8 nearest neighbors (highlighted in gray) are considered for matching with image p1</figcaption></figure>
<!-- --><p>This option can speed up processing by reducing the number of matching pairs, especially when GPS data is available. If no GPS information is provided, this option is disabled, and all image pairs are considered unless <!-- --><a href="#matcher-order">matcher-order</a> is specified.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="matcher-order">matcher-order<!-- --><a href="#matcher-order" class="hash-link" aria-label="Direct link to matcher-order" title="Direct link to matcher-order">​</a></h2>
<!-- --><p>Like <!-- --><a href="#matcher-neighbors">matcher-neighbors</a>, this option decreases the number of candidate pairs for matching based on the sequential order of image filenames. For instance, if you have 3 images sorted by filename:<!-- --></p>
<!-- --><ul>
<!-- --><li><strong>1.JPG</strong></li>
<!-- --><li><strong>2.JPG</strong></li>
<!-- --><li><strong>3.JPG</strong></li>
<!-- --></ul>
<!-- --><p>With this option set to <!-- --><code>1</code>, the program will evaluate matches between:<!-- --></p>
<!-- --><ul>
<!-- --><li><strong>1.JPG</strong> and <!-- --><strong>2.JPG</strong></li>
<!-- --><li><strong>2.JPG</strong> and <!-- --><strong>3.JPG</strong></li>
<!-- --></ul>
<!-- --><p>This is because the &quot;distance&quot; between these image pairs in the list is 1. <!-- --><strong>1.JPG</strong> and <!-- --><strong>3.JPG</strong> have a distance of 2, so this pair will be excluded from matching.<!-- --></p>
<!-- --><p>This option determines the maximum distance between image filenames for them to be considered a matching pair. It is exclusively useful for datasets without GPS information, particularly for expediting the processing of sequentially ordered images, like frames extracted from videos.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="matcher-type">matcher-type<!-- --><a href="#matcher-type" class="hash-link" aria-label="Direct link to matcher-type" title="Direct link to matcher-type">​</a></h2>
<!-- --><p>After preemptive matching finds potential image pairs (as discussed in <!-- --><a href="#matcher-neighbors">matcher-neighbors</a>), further computation identifies the actual image pairs by comparing their features.<!-- --></p>
<!-- --><p>To expedite feature matching, specific algorithms have been developed, given the large number of features in each image.</p>
<!-- --><table><thead><tr><th><strong>Option</strong></th><th><strong>Search For Features With</strong></th></tr></thead><tbody><tr><td>flann</td><td>An index powered by the Fast Library for Approximate Nearest Neighbors</td></tr><tr><td>bow</td><td>A Bag Of Words<!-- --><sup><a href="#user-content-fn-bow" id="user-content-fnref-bow" data-footnote-ref="true" aria-describedby="footnote-label">11</a></sup> approach<!-- --></td></tr></tbody></table>
<!-- --><p>The default method, <!-- --><strong>flann</strong>, is highly versatile, providing an excellent balance between accuracy and speed. <!-- --><strong>bow</strong> is quicker but compatible only with HAHOG features and potentially misses some matches.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="mesh-octree-depth">mesh-octree-depth<!-- --><a href="#mesh-octree-depth" class="hash-link" aria-label="Direct link to mesh-octree-depth" title="Direct link to mesh-octree-depth">​</a></h2>
<!-- --><p>Controls the quality of the 3D textured models. A higher value results in a finer model. However, this comes at the cost of significantly increased processing time. The default value of <!-- --><code>11</code> is suitable for most scenarios. Lower values (<!-- --><code>6-8</code>) can be sufficient in flat areas, while setting it higher (<!-- --><code>12</code>) can improve results in urban areas. When raising this option, consider increasing <!-- --><a href="#mesh-size">mesh-size</a> as finer meshes require more triangles.<!-- --></p>
<!-- --><figure><div class="container_iyx7 padded_zXJG smooth_udfB"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAOCAYAAAAWo42rAAAACXBIWXMAAC4jAAAuIwF4pT92AAAB0ElEQVR4nBXOa1eaAACAYX5DH3bLNptCIio0lBIFJBUUFa9DWxdXmpdW6dY51dlZH/bL3509v+ARft3O+bNd0a0dsZgMsCyDmmcQhmWeNnOeNhvklIIgpnY4nX3j5+srd8s5q9mY6+kFP9YLZldn9Dou8+8RQtmKMZw4nC0jppcu7W6R2c09zy9/eX75Tc3LYJb3ERrVLO0gxSBU6fcM/DDHaNRkub4j+l+xddpBAcE/UQjbWTptlU6QI2jKdDoZypZEWokzHgxYTi8RGnUZryZRtUW0wz2KxQSWmcS2daJRxHZ5w2YxRzCNBIUvHynkY3w+2CFx8Bb9UKF5es7Z9YLxMOLxdoWQSu/SajjkNYl62SAlxUnLIrIiYhZ1qpUyzRMTQZQ/cNL28IKAYRgw+RoyiSJGgy69ThNVTeDYGkIuk6Zkq5iugesoWJbGYDBmvXrg4mKKbiTJqO8QdG2fo0KcaiVFvZ6lVBExzUP6/SH9URfbydFq5BHsooRbkXBsCb+u0Gop+L7CcVGkZKZZX53zsnlAKBx9Qs/HcEpJcrld8oV9PDeNV80T+D5PD/e8Pm4RJOUNcvY9uhEno+2hajFcM8OxbRH0hrSaLbbrJf8Ajnv77CkwbM8AAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="893"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/mesh_octree_depth_comp.924da56.640.png" srcset="/assets/ideal-img/mesh_octree_depth_comp.924da56.640.png 640w,/assets/ideal-img/mesh_octree_depth_comp.07f978e.867.png 867w" alt="mesh-octree-depth 6 and mesh-size 10000 (top) vs. mesh-octree-depth 11 and mesh-size 1000000 (bottom)" width="640" height="893"></noscript></div></div><figcaption class="figcaption__A7e">mesh-octree-depth 6 and mesh-size 10000 (top) vs. mesh-octree-depth 11 and mesh-size 1000000 (bottom)</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="mesh-size">mesh-size<!-- --><a href="#mesh-size" class="hash-link" aria-label="Direct link to mesh-size" title="Direct link to mesh-size">​</a></h2>
<!-- --><p>WebODM Lightning automatically simplifies the textured 3D models by limiting their triangle count. A high triangle count prolongs subsequent processing steps. A low count can reduce model quality, while increasing it can enhance results, especially in urban areas requiring fine building details.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="min-num-features">min-num-features<!-- --><a href="#min-num-features" class="hash-link" aria-label="Direct link to min-num-features" title="Direct link to min-num-features">​</a></h2>
<!-- --><p>This option controls the minimum number of features detected in each image, increasing the potential for finding matches.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG smooth_udfB"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAECAIAAAA4WjmaAAAACXBIWXMAAC4jAAAuIwF4pT92AAAAh0lEQVR4nAF8AIP/ANHBuqKpcai0ea62fKOpd52TntXM28/Ctp6obqCubADWw8awsYWcrGmmsnehp3K1qK/Px9bVw8GqrXyYqWMA1r/HurKVmKJmna5spa12x7/FxcDN18HGt7ORlqJkANjI09bFv52hbZmpY6WzecfBycW/zN7O2dDBtpObXzdgUD0+kIncAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="239"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/image_features.9903742.640.png" srcset="/assets/ideal-img/image_features.9903742.640.png 640w,/assets/ideal-img/image_features.bdf6684.1024.png 1024w" alt="Features (red points) and matches between overlapping images (white lines). min-num-features controls the desired number of red points in each image" width="640" height="239"></noscript></div></div><figcaption class="figcaption__A7e">Features (red points) and matches between overlapping images (white lines). min-num-features controls the desired number of red points in each image</figcaption></figure>
<!-- --><p>Increase this option when mapping areas with few discernible features, like forests.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="optimize-disk-space">optimize-disk-space<!-- --><a href="#optimize-disk-space" class="hash-link" aria-label="Direct link to optimize-disk-space" title="Direct link to optimize-disk-space">​</a></h2>
<!-- --><p>This option is always turned on. No need to worry about it.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="orthophoto-cutline">orthophoto-cutline<!-- --><a href="#orthophoto-cutline" class="hash-link" aria-label="Direct link to orthophoto-cutline" title="Direct link to orthophoto-cutline">​</a></h2>
<!-- --><p>Enabling this option results in the program creating a cutline, which is a polygon within the crop area of the orthophoto that aims to trace feature edges.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAJCAIAAACExCpEAAAACXBIWXMAAC4jAAAuIwF4pT92AAABHklEQVR4nGP49+/f379/////9////99/fhw7c3bp8tZr13f/////37+/DP/+gSQ+ffl04OyG3gVFHRMrypqcZs6v+vsXJM7w5v2rdftnpTV4p9f59c7JmDA7f83KOdnVTkdO7wNJL9881zdHM608vn96c0lDZmNnce/03JrWiCWrJoGk569tzG8InTGno2liUEV7+IRpdd5J2vmF2WsWz33y9AHD+u3z16yc3j4xobjZIb8qvrO7Jzk/NDY1LDrJ9cTRowy3rt5r7k0obbHtnZQyacLUjp7OxHyf2EzrBUs6//35z/D///+T53e29Sd3dZfmlEaFxrvnlvotWdn3/fsPkN0Qj71583r16nkbli2cPaN947rlP358A/v7HwAIX7JDXNvkxwAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="561"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/cutline.54e0da2.640.png" srcset="/assets/ideal-img/cutline.54e0da2.640.png 640w,/assets/ideal-img/cutline.008d29b.1003.png 1003w" alt="Cutline" width="640" height="561"></noscript></div></div><figcaption class="figcaption__A7e">Cutline</figcaption></figure>
<!-- --><p>The resulting cutline can be downloaded from the cloud interface by clicking <!-- --><strong>Download Assets</strong> → <!-- --><strong>All Assets</strong> (<!-- --><code>odm_orthophoto/cutline.gpkg</code>).<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="orthophoto-resolution">orthophoto-resolution<!-- --><a href="#orthophoto-resolution" class="hash-link" aria-label="Direct link to orthophoto-resolution" title="Direct link to orthophoto-resolution">​</a></h2>
<!-- --><p>This option specifies the output resolution of the orthophoto in cm / pixel.</p>
<!-- --><p>See also <!-- --><a href="#dem-resolution">dem-resolution</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pc-classify">pc-classify<!-- --><a href="#pc-classify" class="hash-link" aria-label="Direct link to pc-classify" title="Direct link to pc-classify">​</a></h2>
<!-- --><p>Points in a point cloud can be assigned classification values<!-- --><sup><a href="#user-content-fn-las" id="user-content-fnref-las" data-footnote-ref="true" aria-describedby="footnote-label">12</a></sup> to indicate if they belong to the terrain (ground), a building, a tree (vegetation), or other categories. By default, all points are labeled as <!-- --><em>unclassified</em>, and the software doesn&#x27;t assign specific labels to points. Enabling this option utilizes a Simple Morphological Filter<!-- --><sup><a href="#user-content-fn-smrf" id="user-content-fnref-smrf-2" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup> (SMRF) to identify and classify terrain points as ground. An AI classifier<!-- --><sup><a href="#user-content-fn-openpointclass" id="user-content-fnref-openpointclass" data-footnote-ref="true" aria-describedby="footnote-label">13</a></sup> is then applied to the remaining (non-ground) points to recognize vegetation, buildings, and other structures. This process results in a classified point cloud.<!-- --></p>
<!-- --><figure><div class="container_iyx7 padded_zXJG smooth_udfB"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAACXBIWXMAAA7EAAAOxAGVKw4bAAABZUlEQVR4nAXB4U8SYQDA4fcm4iUaSBPd3hRJp8jhmTpLEIaA6KFysCs80EgMPDAOtXYoq7U+9If/eh4xab6gVj122k8Ytx2Kzoi1q1+ErBGTFQ9fZYS/+oyIlBsUW6f0H064c8v0HmoMht+wOzfsWJdolsPrwjUiZe3z/OOEp55Fs31Ix31Pf5jF+2lj1bM0v1houTxCXdXJHOe4MHNUamkajSO+tk1q9gUfMrs0W030bAmhRKKI0BK++XdMy3WWEykWNvaYW9EIxzZZjOso88uIqaKLWnZZadkkhwWM+yTpKwP56RL/mcNE/jv+0hChdk3k31M2xxaxf+dsj+uYj+fYv7fQx/sUugcE6yYi4GSIe3fsDXrIP8fIrsP6rYvmDNgYH9DyosQaKYRPJpnV8iyUckSreeLtMnrfIH2f5eN1gq3PBjOJI4QyG0YEgiivwiiBNwSX3jItJREZQo1IlDmJEgjxHw4drU0Ck7bUAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="612"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/point_cloud_classification.948f54d.640.png" srcset="/assets/ideal-img/point_cloud_classification.948f54d.640.png 640w,/assets/ideal-img/point_cloud_classification.7061409.1024.png 1024w" alt="Point cloud (top) and classification results (bottom)" width="640" height="612"></noscript></div></div><figcaption class="figcaption__A7e">Point cloud (top) and classification results (bottom)</figcaption></figure>
<!-- --><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td>smrf-scalar</td><td>This parameter makes the threshold dependent on the slope. To enhance results, consider slightly decreasing this value when raising the smrf-threshold, and vice versa..</td></tr><tr><td>smrf-slope</td><td>Set this parameter to the steepest common terrain slope, represented as the ratio of elevation change to horizontal distance change (e.g., 1.5 meters over 10 meters is 1.5 / 10 = 0.15). Increase it for terrains with significant slope variation, like hills and mountains, and reduce it for flat areas. For optimal results, it should be above 0.1 but not exceed 1.2.</td></tr><tr><td>smrf-threshold</td><td>Defines the minimum height (in meters) of non-ground objects. For instance, a setting of 5 meters is suitable for identifying buildings but may not suffice for recognizing cars. To identify cars, lower the value to 2 or even 1.5 meters (the average car height). This parameter significantly influences results.</td></tr><tr><td>smrf-window</td><td>Set this to the size of the largest non-ground feature in meters. If the scene primarily consists of small objects like trees, reduce this value. If there are larger objects like buildings, increase it. It&#x27;s advisable to maintain a value above 10 meters.</td></tr></tbody></table>
<!-- --><p>SMRF has limitations, including occasional misclassification of buildings or trees as ground points (type II errors).</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAICAYAAADA+m62AAAACXBIWXMAAB7CAAAewgFu0HU+AAABJUlEQVR4nBXBzUvCYADA4f2JXQPRQtJiiR/T8HU1p1Nn6lTMGX6sUvMDMiWSokKITkHeCqJrh+jUJTz/oueRfr5/mc2XmOMpteqc5GBKzu6R605I2T0Wzy/8k64flrgzdTx5i2ixj1w9JWbF8BspvAdpvMk4rx9vSE77HiV8jKa0SETqxIM19kJN9kUToRfwCJVGq4NUlpuINYO4y0RsFCm5HcrBMWX1BkNvsalWqNRvkfLmENVnY/octHWLrNvG2h2ST8zQUmf4jTxG1kaKDs7ZDlpUQ1NUv03Se0RFucQQI4zMFXJGJxwTSPpogitySNrfJbFuoe200QJ1FLmI0E/Y0gOUqibS++cX7bsFzcoEJ3lBwexjptsUjCENp8Ps6ZHVasUfWJLWrONBbVYAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="512"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/input_surface_model.edc62f8.640.png" srcset="/assets/ideal-img/input_surface_model.edc62f8.640.png 640w,/assets/ideal-img/input_surface_model.1366932.1024.png 1024w" alt="Input surface model" width="640" height="512"></noscript></div></div><figcaption class="figcaption__A7e">Input surface model</figcaption></figure>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAICAYAAADA+m62AAAACXBIWXMAAB7CAAAewgFu0HU+AAABKElEQVR4nAXBS0sCUQCA0fmN7SqoRRIUiQ8KJdS8jpPaVRMd89mYoaJoU+pIqYEKQbsWFYS7oBYR0UKiZV/nKN+fC4bdR4qVW3JyiJ4fk0uPKJYmZApjru8egT+U6ewFp/ccn2ihBk2EZuKPdvCEawjRwS8veH37QqlXJngdZVTnGcJuoDqqhDwNQvstpGbhC3foXT+gFN011KUkkeUM0WUduV4kaW9y7BsgwxYHhyal0wlKOtlFbJU5shloqxnkWoGUvUnCbxELWwQjJunsCCVmjXDtnSB3Gqi2AonNKqndS+IBi5jWR413SWWHKAlzyKY/T2CjhFjRkdt1jtxtIu4OmujjSjQx2jOU+fsHjek9hn5FTfQohQaU5RgjNaZ/88T0ec7i55d/eBbhFFtPkzkAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="512"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/smrf_model_default.a075320.640.png" srcset="/assets/ideal-img/smrf_model_default.a075320.640.png 640w,/assets/ideal-img/smrf_model_default.9b6ba4c.1024.png 1024w" alt="Terrain model created using default SMRF settings. Note a few houses were incorrectly included, and there are lingering artifacts near the edges of removed objects." width="640" height="512"></noscript></div></div><figcaption class="figcaption__A7e">Terrain model created using default SMRF settings. Note a few houses were incorrectly included, and there are lingering artifacts near the edges of removed objects.</figcaption></figure>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAICAYAAADA+m62AAAACXBIWXMAAB7CAAAewgFu0HU+AAABKUlEQVR4nBXKyy/DcADA8f6Nbki44MI8xpKFzePXx5q1q2UPxkpXkQXRrXuU2DIbEnEhXDhIJMJJuEhEnL6yz/kjfX18c1Z5oORcUjBabBQ6bGbaFIs98oU251dP9Em9ziPxiIes+CTW6siaj6z6yHIVIaoIs8br+ydS2ekSmy2hzLmIkIMys4cWPUKPVTDUJnHVo356h7QV3kcMpNAHs+iDOYzRbVJTB1hLTQwlQCR8bKeLtGEFaJMljHGHxHAOY2SLdOgQKx6QVANk3SebbyGt17pEIzuYU2W0sSLWhEt6oYK53CSpBShmnXQ/ZrwO07FdVsdsxFAOc7JMMnyMPu+hrtRZTFZxvWuk57cPji9ucfMN9tdq2OIE22jjZro0qvfc3L/w8/vHP1iQ4mD5+Cq7AAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="512"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/smrf_model_improved.b1e00c9.640.png" srcset="/assets/ideal-img/smrf_model_improved.b1e00c9.640.png 640w,/assets/ideal-img/smrf_model_improved.35a80f6.1024.png 1024w" alt="An improved terrain model obtained by setting smrf-threshold 0.3
(decreased), smrf-scalar 1.3 (increased), smrf-slope 0.05 (decreased)
and smrf-window 24 (increased)" width="640" height="512"></noscript></div></div><figcaption class="figcaption__A7e">An improved terrain model obtained by setting smrf-threshold 0.3
(decreased), smrf-scalar 1.3 (increased), smrf-slope 0.05 (decreased)
and smrf-window 24 (increased)</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pc-filter">pc-filter<!-- --><a href="#pc-filter" class="hash-link" aria-label="Direct link to pc-filter" title="Direct link to pc-filter">​</a></h2>
<!-- --><p>Noise from the point cloud can be partially removed using a combination of statistical and visibility
filtering. This option sets the standard deviation threshold value for the
statistical filter. In this context standard deviation is a measure of how spread out points are
relative to their neighbors. The filter looks at the closest 16
neighbors for each point and computes their standard deviations, which gives a measure of how far
each point deviates from the average distance to each other point. If a
point is found to be too far away relative to its neighbors, thus having
a standard deviation higher than the threshold, the point is labeled as
an outlier.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAECAYAAAC3OK7NAAAACXBIWXMAAJqLAACaiwH9WadrAAAAqUlEQVR4nGNgYGBg+G9qKvzOwED/tb6+w2N9fe9zWlohBzQ0Avdradn8t7AQAqlhuKWhYXFBXT3vha5u6gtd3ZTDWlqVBzQ1qw9qa9fs1NBoOaulVfRfX9+A4b6hoeU1S8uKV7q6qW/09JJ3a2o27tPSqjuppVV+TFOzar+GRu1zfX0zsKn/AwPFQFZ/0te3fqSn535ZW9v3hq6u8x0dHZNPBgaiDAwMjAC8BDcm+o8xnQAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="250"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/pc_filter.de9d1d3.640.png" srcset="/assets/ideal-img/pc_filter.de9d1d3.640.png 640w,/assets/ideal-img/pc_filter.543cd6a.1024.png 1024w" alt="The gray point is an outlier due to its high standard deviation" width="640" height="250"></noscript></div></div><figcaption class="figcaption__A7e">The gray point is an outlier due to its high standard deviation</figcaption></figure>
<!-- --><p>Adjusting this value too high retains noisy points, and setting it too low may eliminate valid ones. You can disable filtering by setting this option to zero.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pc-quality">pc-quality<!-- --><a href="#pc-quality" class="hash-link" aria-label="Direct link to pc-quality" title="Direct link to pc-quality">​</a></h2>
<!-- --><p>This option affects the density of the point cloud. Higher values use higher resolution images according to a scale factor:</p>
<!-- --><table><thead><tr><th><strong>Option</strong></th><th><strong>Scaling Factor</strong></th></tr></thead><tbody><tr><td>high</td><td>1/4</td></tr><tr><td>medium</td><td>1/8</td></tr><tr><td>low</td><td>1/16</td></tr><tr><td>lowest</td><td>1/32</td></tr></tbody></table>
<!-- --><p>Different image dimensions also correspond to a multiplier value:</p>
<!-- --><table><thead><tr><th><strong>Largest Image Dimension (megapixels)</strong></th><th><strong>Multiplier</strong></th></tr></thead><tbody><tr><td>&lt; 6</td><td>2</td></tr><tr><td>6 - 42</td><td>1</td></tr><tr><td>&gt; 42</td><td>1/2</td></tr></tbody></table>
<!-- --><p>The actual resolution of the images used for point cloud estimation is then calculated with:</p>
<!-- --><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">resolution </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">max</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">320</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> max_image_dimension </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> scaling_factor </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> multiplier</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- --><p>For example, in a dataset with 4000x3000 (12 megapixels) images, setting this option to <!-- --><code>high</code> will use images scaled to 1000 pixels for computing a point cloud:<!-- --></p>
<!-- --><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">image </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">4000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">3000</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">max_image_dimension </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">max</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">image</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># &lt;-- 4000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">megapixels </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> image</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">image</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token operator" style="color:#393A34">/</span><span class="token number" style="color:#36acaa">1000000</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># &lt;-- 12</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">multiplier </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># From table</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">scaling_factor </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token operator" style="color:#393A34">/</span><span class="token number" style="color:#36acaa">4</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># pc-quality: high</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token builtin">max</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">320</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> max_image_dimension </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> scaling_factor </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> multiplier</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># &lt;-- 1000 pixels</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pc-sample">pc-sample<!-- --><a href="#pc-sample" class="hash-link" aria-label="Direct link to pc-sample" title="Direct link to pc-sample">​</a></h2>
<!-- --><p>This option imposes an upper limit on the density of the dense point cloud, defined as a radius in meters that ensures no two points are closer than the specified value. For instance, a setting of <!-- --><code>0.05</code> ensures points are at least 5 centimeter (0.05 meters) apart. This option is always set to at least <!-- --><code>0.01</code>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pc-skip-geometric">pc-skip-geometric<!-- --><a href="#pc-skip-geometric" class="hash-link" aria-label="Direct link to pc-skip-geometric" title="Direct link to pc-skip-geometric">​</a></h2>
<!-- --><p>A geometric refinement process is used to improve the point cloud. This process can take some time and can be skipped by using this option.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAADCAYAAACqPZ51AAAACXBIWXMAABXWAAAV1gHWa1n9AAAAe0lEQVR4nBXITQuCMACA4f3MmhlKh5ia1CE61FYSmxRIh+oiROEHdpo/8Y2e4yPW40g+dKRtS9r1qNebzf++HUnTkPUDSdMitt6jnCatP0TVndBV7PyIsnuWz5r49mBSOITUluB8ZaZL5Mowjw3BwTItSkJzQeZHosWJH8zdS+td3cWYAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="186"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/pc_skip_geometric.1e29e16.640.png" srcset="/assets/ideal-img/pc_skip_geometric.1e29e16.640.png 640w,/assets/ideal-img/pc_skip_geometric.131d733.1024.png 1024w" alt="Elevation model with defaults (left) vs. pc-skip-geometric (right). Improved building and car definition on the left." width="640" height="186"></noscript></div></div><figcaption class="figcaption__A7e">Elevation model with defaults (left) vs. pc-skip-geometric (right). Improved building and car definition on the left.</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="primary-band">primary-band<!-- --><a href="#primary-band" class="hash-link" aria-label="Direct link to primary-band" title="Direct link to primary-band">​</a></h2>
<!-- --><p>This option selects the band name (Red, Blue, Green, NIR, etc.) for reconstructing multispectral datasets. The chosen band name must match the <!-- --><strong>Camera::BandName</strong> EXIF<!-- --><sup><a href="#user-content-fn-exif" id="user-content-fnref-exif-2" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup> tag. Only the images associated with this band will be utilized for 3D reconstruction.<!-- --></p>
<!-- --><p>By setting it to <!-- --><code>auto</code> (the default), the band will be automatically selected.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="radiometric-calibration">radiometric-calibration<!-- --><a href="#radiometric-calibration" class="hash-link" aria-label="Direct link to radiometric-calibration" title="Direct link to radiometric-calibration">​</a></h2>
<!-- --><p>Radiometric calibration converts pixel values (digital numbers) into reflectance. WebODM Lightning can automate radiometric calibration and compute reflectance and temperature values for various sensors<!-- --><sup><a href="#user-content-fn-sensors" id="user-content-fnref-sensors" data-footnote-ref="true" aria-describedby="footnote-label">14</a></sup>.<!-- --></p>
<!-- --><table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>none</td><td>No radiometric calibration (digital number outputs)</td></tr><tr><td>camera</td><td>Applies black level, vignetting, gain, and exposure corrections based on information from the EXIF tags. Additionally, computes absolute temperature values when applicable</td></tr><tr><td>camera+sun</td><td>Same as <!-- --><code>camera</code>, but also applies corrections from a downwelling light sensor (DLS) when available<!-- --></td></tr></tbody></table>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="rerun-from">rerun-from<!-- --><a href="#rerun-from" class="hash-link" aria-label="Direct link to rerun-from" title="Direct link to rerun-from">​</a></h2>
<!-- --><p>This option cannot be used. Don&#x27;t worry about it.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="rolling-shutter">rolling-shutter<!-- --><a href="#rolling-shutter" class="hash-link" aria-label="Direct link to rolling-shutter" title="Direct link to rolling-shutter">​</a></h2>
<!-- --><p>Enables rolling shutter correction to enhance reconstruction accuracy in datasets captured with rolling shutter sensors. If GPS information is present in the input images, and the dataset was captured with a single camera, WebODM Lightning can correct for rolling shutter distortion by initially estimating the aircraft&#x27;s velocity at the time each picture was taken. Some cameras store velocity information in the EXIF/XMP tags of the images (<!-- --><strong>SpeedX</strong>, <!-- --><strong>SpeedY</strong>, and <!-- --><strong>SpeedZ</strong>), which provides the most reliable estimate. In the absence of these tags, velocity is estimated based on the time and positional differences between consecutive images.<!-- --></p>
<!-- --><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">speed </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">position_2 </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> position_1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">time_2 </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> time_1</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- --><p>The accuracy of the formula mentioned above can be compromised in situations where the drone is stationary while capturing a picture, as it assumes continuous motion and sequential image capture. In such cases, the calculation may yield incorrect estimates, potentially degrading results. However, as long as most images can be assigned accurate velocity estimates, rolling shutter correction can still be effective, even if a few images have incorrect estimates.</p>
<!-- --><p>Once the velocities are estimated, the program searches a database to retrieve the rolling shutter readout time for the camera sensor. This readout time represents the duration (in milliseconds) required for the sensor to capture an image. In cases where your camera is not listed in the database, a warning will appear in the task output:</p>
<!-- --><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[WARNING] Rolling shutter readout time for &quot;make model&quot; is not in </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">our database, using default of 30ms which might be incorrect.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<!-- --><figure><div class="container_iyx7 padded_zXJG"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAYAAAD68A/GAAAACXBIWXMAAC4jAAAuIwF4pT92AAAApElEQVR4nFWO2QqDMBRE8/9fVQp9LhT61FLRxsRoY9xQsUlOUbrQgWHg3sMwQpcW2w6smuYZZSpq1+K9x84OtzT4GBC3VFLZegNlrlHasCxPYojb7SNhqgdSF4zTzPl4osz19gghEOLbISAKU5HeFdck21IVJdY1v6oI/ukRUhUkWc7llrLOkNr8gyu7NnbDQNN21K6h7Xq6fmAcp+/GvnbsdwdegKDlmu27buQAAAAASUVORK5CYII=&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="409"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/task_output_toggle.a880b19.640.png" srcset="/assets/ideal-img/task_output_toggle.a880b19.640.png 640w,/assets/ideal-img/task_output_toggle.c1deaf8.1024.png 1024w" alt="You can access the task output by expanding a task from the projects list and toggling the Task Output button to On. If the task output is truncated, first you&#x27;ll need to download the task output to a file by pressing the Download To File button" width="640" height="409"></noscript></div></div><figcaption class="figcaption__A7e">You can access the task output by expanding a task from the projects list and toggling the Task Output button to On. If the task output is truncated, first you&#x27;ll need to download the task output to a file by pressing the Download To File button</figcaption></figure>
<!-- --><p>With known camera velocities and sensor readout times, the correction is applied by shifting image features based on these factors. Subsequently, the reconstruction is repeated, effectively doubling the processing time but enhancing accuracy in datasets influenced by rolling shutter distortions.</p>
<!-- --><div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info<!-- --></div><div class="admonitionContent_BuS1"><p>You can estimate the correct sensor value by creating a cost-effective calibration device using an Arduino. Detailed instructions are available at <!-- --><a href="https://github.com/OpenDroneMap/RSCalibration" target="_blank" rel="noopener noreferrer">github.com/OpenDroneMap/RSCalibration</a>.<!-- --></p></div></div>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="rolling-shutter-readout">rolling-shutter-readout<!-- --><a href="#rolling-shutter-readout" class="hash-link" aria-label="Direct link to rolling-shutter-readout" title="Direct link to rolling-shutter-readout">​</a></h2>
<!-- --><p>Overrides the default sensor readout time value used for rolling shutter correction.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="sfm-algorithm">sfm-algorithm<!-- --><a href="#sfm-algorithm" class="hash-link" aria-label="Direct link to sfm-algorithm" title="Direct link to sfm-algorithm">​</a></h2>
<!-- --><p>There are three methods to reconstruct a scene:</p>
<!-- --><table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td>incremental</td><td>a general-purpose approach suitable for all scenes. It supports multiple cameras and adds them to the reconstruction incrementally, ensuring high reliability.</td></tr><tr><td>triangulation</td><td>If gimbal angles and GPS information are available, camera positions are initialized from those values in a single step and then iteratively improved. This method can yield better results and may be slightly faster than <!-- --><code>incremental</code>. However, it&#x27;s experimental and may not work with all camera types.<!-- --></td></tr><tr><td>planar</td><td>For flat scenes, like a farm field, captured with a single camera at a constant altitude and a downward-facing view (nadir), this option is recommended. It processes 5-10 times faster than the <!-- --><code>incremental</code> method and is compatible with multispectral datasets.<!-- --></td></tr></tbody></table>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="sfm-no-partial">sfm-no-partial<!-- --><a href="#sfm-no-partial" class="hash-link" aria-label="Direct link to sfm-no-partial" title="Direct link to sfm-no-partial">​</a></h2>
<!-- --><p>This option is always turned on. No need to worry about it.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="skip-3dmodel">skip-3dmodel<!-- --><a href="#skip-3dmodel" class="hash-link" aria-label="Direct link to skip-3dmodel" title="Direct link to skip-3dmodel">​</a></h2>
<!-- --><p>If a user only needs an orthophoto, there&#x27;s no need to create a complete 3D model. This option saves time by skipping the steps for generating a 3D model. Instead, it creates a 2.5D model, where elevation is extruded from the ground plane. While not a full 3D model, it works effectively for rendering orthophotos, although it can&#x27;t accurately represent objects like overhangs.</p>
<!-- --><p>See also <!-- --><a href="#use-3dmesh">use-3dmesh</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="skip-band-alignment">skip-band-alignment<!-- --><a href="#skip-band-alignment" class="hash-link" aria-label="Direct link to skip-band-alignment" title="Direct link to skip-band-alignment">​</a></h2>
<!-- --><p>When capturing multispectral images, the sensors for each band are often slightly misaligned, causing small misalignments between the image bands. ODM automatically aligns these bands as part of its multispectral processing. If manual alignment has already been done using other software, you can disable the automatic alignment using this option.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="skip-orthophoto">skip-orthophoto<!-- --><a href="#skip-orthophoto" class="hash-link" aria-label="Direct link to skip-orthophoto" title="Direct link to skip-orthophoto">​</a></h2>
<!-- --><p>If you don&#x27;t require an orthophoto, this option can save you time by skipping the orthophoto generation step.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="skip-report">skip-report<!-- --><a href="#skip-report" class="hash-link" aria-label="Direct link to skip-report" title="Direct link to skip-report">​</a></h2>
<!-- --><p>If you don&#x27;t require a PDF report, this option can save you some time by skipping the report generation step.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="sky-removal">sky-removal<!-- --><a href="#sky-removal" class="hash-link" aria-label="Direct link to sky-removal" title="Direct link to sky-removal">​</a></h2>
<!-- --><p>Utilizes AI methods to automatically create <!-- --><a href="/how-to/image-masks">image masks</a> for sky removal. This is beneficial for datasets that include sky portions, especially in cases where oblique images are used for 3D structure capture. Sky areas can introduce noise in the 3D model, and this option helps in its reduction.<!-- --></p>
<!-- --><figure><div class="container_iyx7 padded_zXJG smooth_udfB"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAALCAYAAABGbhwYAAAACXBIWXMAABXXAAAV1wEELLsZAAABnElEQVR4nB3Da09ScQDA4f83gKWsVi9CYybOkcoZR6Wt7K4QRMCRq3q4nTM4XBygE4iblVhJxYtaW2/cetHWZX2E1hc6H+HX5rM9wmKxMz09x+Liba5dXeDhpsL9TQXX8l3kO0Hmb21gtc4i7PZ7PHiSRasOSes99OY7MvsnF3e1QwqHI9xrCmJ1tUz/+BOaXsaoHNAdnNAbviKb0wn6A5y+fU21PUY8enzGcfeUip4kV8jQG3ToDlrkC7v4fRv02/vEUwOEmvnHi6Pv5PNnROOfCcdGBKM9ovEJEaWPpr8hkfiJkOUykmSwsmLgkWosL+kXPVIVSargdmvIch5htc5waWoOx00Z22UnDuc61x0ebFfmmZldYsrmxGq5gVhwKoRjTRJqnefJOrnqS1Sjhy9cJBRRiSWLuFwJhNd7RLv1nkatxEGjwccPYyaTMc16FSUSZNhpse4tIEKhcwadEVp2j3BcJ1dskNHKbCd1tnxPqRkltnwjhKr+NY3SbzOV/mYq27/MwLMvpj8wMZXYD1OJnZupva9meueP+R/qVOIvU3e33wAAAABJRU5ErkJggg==&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="711"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/sky_removal.8825760.640.png" srcset="/assets/ideal-img/sky_removal.8825760.640.png 640w,/assets/ideal-img/sky_removal.340e22d.1024.png 1024w" alt="3D point cloud without (top) and with sky masks (bottom). Sceaux castle model generated from photos by Pierre Moulon" width="640" height="711"></noscript></div></div><figcaption class="figcaption__A7e">3D point cloud without (top) and with sky masks (bottom). Sceaux castle model generated from photos by Pierre Moulon</figcaption></figure>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="smrf-scalar">smrf-scalar<!-- --><a href="#smrf-scalar" class="hash-link" aria-label="Direct link to smrf-scalar" title="Direct link to smrf-scalar">​</a></h2>
<!-- --><p>Sets the scalar variable for SMRF. See <!-- --><a href="#pc-classify">pc-classify</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="smrf-slope">smrf-slope<!-- --><a href="#smrf-slope" class="hash-link" aria-label="Direct link to smrf-slope" title="Direct link to smrf-slope">​</a></h2>
<!-- --><p>Sets the slope variable for SMRF. See <!-- --><a href="#pc-classify">pc-classify</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="smrf-threshold">smrf-threshold<!-- --><a href="#smrf-threshold" class="hash-link" aria-label="Direct link to smrf-threshold" title="Direct link to smrf-threshold">​</a></h2>
<!-- --><p>Sets the threshold variable for SMRF. See <!-- --><a href="#pc-classify">pc-classify</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="smrf-window">smrf-window<!-- --><a href="#smrf-window" class="hash-link" aria-label="Direct link to smrf-window" title="Direct link to smrf-window">​</a></h2>
<!-- --><p>Sets the window variable for SMRF. See <!-- --><a href="#pc-classify">pc-classify</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="texturing-keep-unseen-faces">texturing-keep-unseen-faces<!-- --><a href="#texturing-keep-unseen-faces" class="hash-link" aria-label="Direct link to texturing-keep-unseen-faces" title="Direct link to texturing-keep-unseen-faces">​</a></h2>
<!-- --><p>By default, if a triangle in the 3D textured model isn&#x27;t visible by any camera, it&#x27;s removed from the output.</p>
<!-- --><figure><div class="container_iyx7 padded_zXJG smooth_udfB"><div style="background-size:cover;background-repeat:no-repeat;position:relative;background-image:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAMCAYAAABbayygAAAACXBIWXMAAC4jAAAuIwF4pT92AAABrUlEQVR4nCXPTWvTcADA4f9FT4PhYXjYxk4yWetW02S1rFnWrknTvDRt7Ytdte3apunL2o4xpiAyEEEU9eynEEH0oEdBxgQV2UVwn+Un0sPzAR4xN3edK1evEQpJdFotHC+J7kTRTYW0KePYNlbWRaysqCwtqUjRBIlUCMOKYXtxdrJhqqUCec8htrWOkKQu0ajPxsYD1sIZMlYC24tQKmdpN7pElDCemUfo+gv+M4yXGPprTKtPo+FxevKMnt9ATUq0K21Evf6JmY/Uah/Yq73nZPqW48NHuPc8csU2e3ePEb5/zsx3RsPfjA8uGA7PCfrf8IMzgv4PBoNfiIWFNebnbyDdTtHtDMgVHcx8GssxsFydglen6DUQy8txFhfjyJsx7mir6KZMNiejmatUSjlcV0eO30TIch9FCVBiCdYjEUwnju1FqVRd2s2AiHKLglVCGMYbdP0pqraDltwmndmi2Sxx+vA5vV6L7d1N9qsdxP36Z/LFVyQ0BVVTSe1mmPSfcDR9jF12sLzybD2dXjIYnNHaf4fvf6EXfGV08JPh6ILR6A+T8SXjyV/+ARA78NJ7wX7hAAAAAElFTkSuQmCC&quot;)"><svg style="width:100%;height:auto;max-width:100%;margin-bottom:-4px" width="640" height="763"></svg><noscript><img style="width:100%;height:auto;max-width:100%;margin-bottom:-4px;position:absolute;top:0;left:0" src="/assets/ideal-img/texturing_keep_unseen_faces.11598fa.640.png" srcset="/assets/ideal-img/texturing_keep_unseen_faces.11598fa.640.png 640w,/assets/ideal-img/texturing_keep_unseen_faces.d483d4c.1024.png 1024w" alt="Unseen faces are removed from the textured mesh (top) vs. faces are kept with no color (bottom)" width="640" height="763"></noscript></div></div><figcaption class="figcaption__A7e">Unseen faces are removed from the textured mesh (top) vs. faces are kept with no color (bottom)</figcaption></figure>
<!-- --><p>This option directs the program to retain all triangles.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="texturing-single-material">texturing-single-material<!-- --><a href="#texturing-single-material" class="hash-link" aria-label="Direct link to texturing-single-material" title="Direct link to texturing-single-material">​</a></h2>
<!-- --><p>The 3D models created by WebODM Lightning are in the Wavefront OBJ<!-- --><sup><a href="#user-content-fn-obj" id="user-content-fnref-obj" data-footnote-ref="true" aria-describedby="footnote-label">15</a></sup> format. This format supports storing color information across multiple image files (textures). Each texture in the model is linked to a &quot;material.&quot; WebODM Lightning typically uses multiple materials and textures when generating OBJ files by default. However, some software may have issues opening OBJs with multiple materials, or performing certain operations on meshes with multiple materials, which can be complex. This is especially true when editing the mesh in programs like Blender<!-- --><sup><a href="#user-content-fn-blender" id="user-content-fnref-blender" data-footnote-ref="true" aria-describedby="footnote-label">16</a></sup>.<!-- --></p>
<!-- --><p>Enabling this option will produce an OBJ file with a single material.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="texturing-skip-global-seam-leveling">texturing-skip-global-seam-leveling<!-- --><a href="#texturing-skip-global-seam-leveling" class="hash-link" aria-label="Direct link to texturing-skip-global-seam-leveling" title="Direct link to texturing-skip-global-seam-leveling">​</a></h2>
<!-- --><p>Images with significant color variations caused by differences in illumination and exposure need to be merged using a global optimization process. This process slightly affects reflectance/temperature values when processing multispectral datasets and it might be desirable to enable this option to turn it off.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tiles">tiles<!-- --><a href="#tiles" class="hash-link" aria-label="Direct link to tiles" title="Direct link to tiles">​</a></h2>
<!-- --><p>This option creates static TMS<!-- --><sup><a href="#user-content-fn-tms" id="user-content-fnref-tms" data-footnote-ref="true" aria-describedby="footnote-label">17</a></sup> tiles for orthophotos and DEMs, ideal for hosting and sharing maps on websites. These tiles work seamlessly with various viewers, like Leaflet<!-- --><sup><a href="#user-content-fn-leaflet" id="user-content-fnref-leaflet" data-footnote-ref="true" aria-describedby="footnote-label">18</a></sup>. DEM tiles are produced with a colored hillshade style and can be downloaded from the cloud interface by clicking on the <!-- --><strong>Download Assets</strong> button.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-3dmesh">use-3dmesh<!-- --><a href="#use-3dmesh" class="hash-link" aria-label="Direct link to use-3dmesh" title="Direct link to use-3dmesh">​</a></h2>
<!-- --><p>By default, a 2.5D textured mesh is used for orthophoto rendering, which usually works well for most aerial datasets. However, it may yield suboptimal results, especially when nadir images (images with the camera pointed straight or nearly straight at the ground) are missing. Furthermore, for specific scenes like single building orbits with oblique images, a 2.5D mesh may not perform well.</p>
<!-- --><p>This option instructs the program to utilize the full 3D model for orthophoto generation while skipping the creation of the 2.5D model. For additional information, see <!-- --><a href="#skip-3dmodel">skip-3dmodel</a>.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-exif">use-exif<!-- --><a href="#use-exif" class="hash-link" aria-label="Direct link to use-exif" title="Direct link to use-exif">​</a></h2>
<!-- --><p>When a GCP file is uploaded with a dataset, it is always used for georeferencing. Enabling this option causes the program to disregard the GCP file and rely on location information from the images&#x27; EXIF<!-- --><sup><a href="#user-content-fn-exif" id="user-content-fnref-exif-3" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup> tags instead.<!-- --></p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-fixed-camera-params">use-fixed-camera-params<!-- --><a href="#use-fixed-camera-params" class="hash-link" aria-label="Direct link to use-fixed-camera-params" title="Direct link to use-fixed-camera-params">​</a></h2>
<!-- --><p>Camera internal parameters are estimated and refined during reconstruction. Poor image capture practices can lead to incorrect estimations and a &quot;doming&quot; effect. Enabling this option keeps camera parameters fixed, potentially improving results when images have little geometric distortion.</p>
<!-- --><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning<!-- --></div><div class="admonitionContent_BuS1"><p>This option will not magically fix problems associated with poor image captures.</p></div></div>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-hybrid-bundle-adjustment">use-hybrid-bundle-adjustment<!-- --><a href="#use-hybrid-bundle-adjustment" class="hash-link" aria-label="Direct link to use-hybrid-bundle-adjustment" title="Direct link to use-hybrid-bundle-adjustment">​</a></h2>
<!-- --><p>This option increases the number of times that bundle adjustment is performed.</p>
<!-- --><p>Turning on this option increases the total run-time, but can help increase the accuracy of the reconstruction in larger datasets that exhibit doming.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="video-limit">video-limit<!-- --><a href="#video-limit" class="hash-link" aria-label="Direct link to video-limit" title="Direct link to video-limit">​</a></h2>
<!-- --><p>WebODM Lightning can process video files (.mp4, .mov, .lrv, and .ts) by extracting image frames at regular intervals. The program automatically filters out blurry and dark frames.</p>
<!-- --><p>For DJI drones, if a matching subtitle (.srt) file is available, it will be used to add GPS information to the extracted images. The subtitle file should have the same filename as the video file, and it is case-sensitive. For example, <!-- --><strong>video.mp4</strong> should have a corresponding <!-- --><strong>video.srt</strong> file.<!-- --></p>
<!-- --><p>This option allows you to set the number of images to extract from the video files.</p>
<!-- --><h2 class="anchor anchorWithStickyNavbar_LWe7" id="video-resolution">video-resolution<!-- --><a href="#video-resolution" class="hash-link" aria-label="Direct link to video-resolution" title="Direct link to video-resolution">​</a></h2>
<!-- --><p>This option defines the resolution of the images extracted from video files. For instance, if a video file has a resolution of 3840x2160 pixels and set this option to 2000, the extracted images will be 2000x1125 pixels in resolution.</p>
<!-- --><p>See also <!-- --><a href="#video-limit">video-limit</a>.<!-- --></p>
<!-- --><section data-footnotes="true" class="footnotes"><h2 class="anchor anchorWithStickyNavbar_LWe7 sr-only" id="footnote-label">Footnotes<!-- --><a href="#footnote-label" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes">​</a></h2>
<!-- --><ol>
<!-- --><li id="user-content-fn-exif">
<!-- --><p>EXIF Tags: <!-- --><a href="https://exiftool.org/TagNames/EXIF.html" target="_blank" rel="noopener noreferrer">exiftool.org/TagNames/EXIF.html</a> <!-- --><a href="#user-content-fnref-exif" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a> <!-- --><a href="#user-content-fnref-exif-2" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<!-- --><sup>2</sup></a> <!-- --><a href="#user-content-fnref-exif-3" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<!-- --><sup>3</sup></a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-xmp">
<!-- --><p>XMP Tags: <!-- --><a href="https://exiftool.org/TagNames/XMP.html" target="_blank" rel="noopener noreferrer">exiftool.org/TagNames/XMP.html</a> <!-- --><a href="#user-content-fnref-xmp" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-smrf">
<!-- --><p>SMRF: A Simple Morphological Filter for Ground Identification of LIDAR Data. <!-- --><a href="http://tpingel.org/code/smrf/smrf.html" target="_blank" rel="noopener noreferrer">tpingel.org/code/smrf/smrf.html</a> <!-- --><a href="#user-content-fnref-smrf" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a> <!-- --><a href="#user-content-fnref-smrf-2" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<!-- --><sup>2</sup></a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-sift">
<!-- --><p>SIFT: Scale Invariant Feature Transform. <!-- --><a href="https://cs.ubc.ca/~lowe/papers/ijcv04.pdf" target="_blank" rel="noopener noreferrer">cs.ubc.ca/~lowe/papers/ijcv04.pdf</a> <!-- --><a href="#user-content-fnref-sift" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-dspsift">
<!-- --><p>DSP-SIFT: Domain-Size Pooling in Local Descriptors. <!-- --><a href="https://arxiv.org/pdf/1412.8556.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1412.8556.pdf</a> <!-- --><a href="#user-content-fnref-dspsift" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-akaze">
<!-- --><p>AKAZE: Accelerated-KAZE. KAZE is a Japanese word that means <!-- --><em>wind</em> (a tribute to Iijima, the father of scale space analysis). <!-- --><a href="http://robesafe.com/personal/pablo.alcantarilla/papers/Alcantarilla13bmvc.pdf" target="_blank" rel="noopener noreferrer">robesafe.com/personal/pablo.alcantarilla/papers/Alcantarilla13bmvc.pdf</a> <!-- --><a href="#user-content-fnref-akaze" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-hahog">
<!-- --><p>HAHOG: Hessian Affine (point detector) + Histogram of Oriented Gradients (descriptor). <!-- --><a href="https://github.com/mapillary/OpenSfM/blob/main/opensfm/src/features/src/hahog.cc" target="_blank" rel="noopener noreferrer">github.com/mapillary/OpenSfM/blob/main/opensfm/src/features/src/hahog.cc</a> <!-- --><a href="#user-content-fnref-hahog" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-orb">
<!-- --><p>ORB: Oriented FAST (point detector) and Rotated BRIEF (descriptor). <!-- --><a href="https://gwylab.com/download/ORB_2012.pdf" target="_blank" rel="noopener noreferrer">gwylab.com/download/ORB_2012.pdf</a> <!-- --><a href="#user-content-fnref-orb" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-rtk">
<!-- --><p>RTK: Real Time Kinematic is a technique used to increase the accuracy of GPS positions using a stationary base station that sends out correctional data to the drone. <!-- --><a href="#user-content-fnref-rtk" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-delaunay">
<!-- --><p>Delaunay Triangulation: <!-- --><a href="https://en.wikipedia.org/wiki/Delaunay_triangulation" target="_blank" rel="noopener noreferrer">en.wikipedia.org/wiki/Delaunay_triangulation</a> <!-- --><a href="#user-content-fnref-delaunay" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-bow">
<!-- --><p>Bag-of-words model in computer vision: <!-- --><a href="https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision" target="_blank" rel="noopener noreferrer">en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision</a> <!-- --><a href="#user-content-fnref-bow" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-las">
<!-- --><p>LAS 1.4 Specification: <!-- --><a href="https://asprs.org/wp-content/uploads/2010/12/LAS_1_4_r13.pdf" target="_blank" rel="noopener noreferrer">asprs.org/wp-content/uploads/2010/12/LAS_1_4_r13.pdf</a> <!-- --><a href="#user-content-fnref-las" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-openpointclass">
<!-- --><p>OpenPointClass: Fast and memory efficient semantic segmentation of 3D point clouds. <!-- --><a href="https://github.com/uav4geo/openpointclass" target="_blank" rel="noopener noreferrer">github.com/uav4geo/openpointclass</a> <!-- --><a href="#user-content-fnref-openpointclass" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-sensors">
<!-- --><p>Supported Multispectral Hardware: <!-- --><a href="https://docs.opendronemap.org/multispectral/#hardware" target="_blank" rel="noopener noreferrer">docs.opendronemap.org/multispectral/#hardware</a> <!-- --><a href="#user-content-fnref-sensors" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-obj">
<!-- --><p>Wavefront OBJ: <!-- --><a href="https://en.wikipedia.org/wiki/Wavefront_.obj_file" target="_blank" rel="noopener noreferrer">en.wikipedia.org/wiki/Wavefront_.obj_file</a> <!-- --><a href="#user-content-fnref-obj" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-blender">
<!-- --><p>Blender: <!-- --><a href="https://blender.org" target="_blank" rel="noopener noreferrer">blender.org</a> <!-- --><a href="#user-content-fnref-blender" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-tms">
<!-- --><p>TMS: Tile Map Service: <!-- --><a href="https://wiki.openstreetmap.org/wiki/TMS" target="_blank" rel="noopener noreferrer">wiki.openstreetmap.org/wiki/TMS</a> <!-- --><a href="#user-content-fnref-tms" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --><li id="user-content-fn-leaflet">
<!-- --><p>Leaflet: <!-- --><a href="https://leafletjs.com/" target="_blank" rel="noopener noreferrer">leafletjs.com/</a> <!-- --><a href="#user-content-fnref-leaflet" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
<!-- --></li>
<!-- --></ol>
<!-- --></section></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/references/"><div class="pagination-nav__sublabel">Previous<!-- --></div><div class="pagination-nav__label">References</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/references/create-successful-maps"><div class="pagination-nav__sublabel">Next<!-- --></div><div class="pagination-nav__label">Create Successful Maps</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#3d-tiles" class="table-of-contents__link toc-highlight">3d-tiles</a></li><li><a href="#auto-boundary" class="table-of-contents__link toc-highlight">auto-boundary</a></li><li><a href="#auto-boundary-distance" class="table-of-contents__link toc-highlight">auto-boundary-distance</a></li><li><a href="#bg-removal" class="table-of-contents__link toc-highlight">bg-removal</a></li><li><a href="#boundary" class="table-of-contents__link toc-highlight">boundary</a></li><li><a href="#camera-lens" class="table-of-contents__link toc-highlight">camera-lens</a></li><li><a href="#cameras" class="table-of-contents__link toc-highlight">cameras</a></li><li><a href="#crop" class="table-of-contents__link toc-highlight">crop</a></li><li><a href="#dem-decimation" class="table-of-contents__link toc-highlight">dem-decimation</a></li><li><a href="#dem-euclidean-map" class="table-of-contents__link toc-highlight">dem-euclidean-map</a></li><li><a href="#dem-gapfill-steps" class="table-of-contents__link toc-highlight">dem-gapfill-steps</a></li><li><a href="#dem-resolution" class="table-of-contents__link toc-highlight">dem-resolution</a></li><li><a href="#dsm" class="table-of-contents__link toc-highlight">dsm</a></li><li><a href="#dtm" class="table-of-contents__link toc-highlight">dtm</a></li><li><a href="#end-with" class="table-of-contents__link toc-highlight">end-with</a></li><li><a href="#fast-orthophoto" class="table-of-contents__link toc-highlight">fast-orthophoto</a></li><li><a href="#feature-quality" class="table-of-contents__link toc-highlight">feature-quality</a></li><li><a href="#feature-type" class="table-of-contents__link toc-highlight">feature-type</a></li><li><a href="#force-gps" class="table-of-contents__link toc-highlight">force-gps</a></li><li><a href="#gps-accuracy" class="table-of-contents__link toc-highlight">gps-accuracy</a></li><li><a href="#matcher-neighbors" class="table-of-contents__link toc-highlight">matcher-neighbors</a></li><li><a href="#matcher-order" class="table-of-contents__link toc-highlight">matcher-order</a></li><li><a href="#matcher-type" class="table-of-contents__link toc-highlight">matcher-type</a></li><li><a href="#mesh-octree-depth" class="table-of-contents__link toc-highlight">mesh-octree-depth</a></li><li><a href="#mesh-size" class="table-of-contents__link toc-highlight">mesh-size</a></li><li><a href="#min-num-features" class="table-of-contents__link toc-highlight">min-num-features</a></li><li><a href="#optimize-disk-space" class="table-of-contents__link toc-highlight">optimize-disk-space</a></li><li><a href="#orthophoto-cutline" class="table-of-contents__link toc-highlight">orthophoto-cutline</a></li><li><a href="#orthophoto-resolution" class="table-of-contents__link toc-highlight">orthophoto-resolution</a></li><li><a href="#pc-classify" class="table-of-contents__link toc-highlight">pc-classify</a></li><li><a href="#pc-filter" class="table-of-contents__link toc-highlight">pc-filter</a></li><li><a href="#pc-quality" class="table-of-contents__link toc-highlight">pc-quality</a></li><li><a href="#pc-sample" class="table-of-contents__link toc-highlight">pc-sample</a></li><li><a href="#pc-skip-geometric" class="table-of-contents__link toc-highlight">pc-skip-geometric</a></li><li><a href="#primary-band" class="table-of-contents__link toc-highlight">primary-band</a></li><li><a href="#radiometric-calibration" class="table-of-contents__link toc-highlight">radiometric-calibration</a></li><li><a href="#rerun-from" class="table-of-contents__link toc-highlight">rerun-from</a></li><li><a href="#rolling-shutter" class="table-of-contents__link toc-highlight">rolling-shutter</a></li><li><a href="#rolling-shutter-readout" class="table-of-contents__link toc-highlight">rolling-shutter-readout</a></li><li><a href="#sfm-algorithm" class="table-of-contents__link toc-highlight">sfm-algorithm</a></li><li><a href="#sfm-no-partial" class="table-of-contents__link toc-highlight">sfm-no-partial</a></li><li><a href="#skip-3dmodel" class="table-of-contents__link toc-highlight">skip-3dmodel</a></li><li><a href="#skip-band-alignment" class="table-of-contents__link toc-highlight">skip-band-alignment</a></li><li><a href="#skip-orthophoto" class="table-of-contents__link toc-highlight">skip-orthophoto</a></li><li><a href="#skip-report" class="table-of-contents__link toc-highlight">skip-report</a></li><li><a href="#sky-removal" class="table-of-contents__link toc-highlight">sky-removal</a></li><li><a href="#smrf-scalar" class="table-of-contents__link toc-highlight">smrf-scalar</a></li><li><a href="#smrf-slope" class="table-of-contents__link toc-highlight">smrf-slope</a></li><li><a href="#smrf-threshold" class="table-of-contents__link toc-highlight">smrf-threshold</a></li><li><a href="#smrf-window" class="table-of-contents__link toc-highlight">smrf-window</a></li><li><a href="#texturing-keep-unseen-faces" class="table-of-contents__link toc-highlight">texturing-keep-unseen-faces</a></li><li><a href="#texturing-single-material" class="table-of-contents__link toc-highlight">texturing-single-material</a></li><li><a href="#texturing-skip-global-seam-leveling" class="table-of-contents__link toc-highlight">texturing-skip-global-seam-leveling</a></li><li><a href="#tiles" class="table-of-contents__link toc-highlight">tiles</a></li><li><a href="#use-3dmesh" class="table-of-contents__link toc-highlight">use-3dmesh</a></li><li><a href="#use-exif" class="table-of-contents__link toc-highlight">use-exif</a></li><li><a href="#use-fixed-camera-params" class="table-of-contents__link toc-highlight">use-fixed-camera-params</a></li><li><a href="#use-hybrid-bundle-adjustment" class="table-of-contents__link toc-highlight">use-hybrid-bundle-adjustment</a></li><li><a href="#video-limit" class="table-of-contents__link toc-highlight">video-limit</a></li><li><a href="#video-resolution" class="table-of-contents__link toc-highlight">video-resolution</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://webodm.net/faq" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQ<!-- --></a></li></ul></div><div class="col footer__col"><div class="footer__title">Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://webodm.net/dashboard" target="_blank" rel="noopener noreferrer" class="footer__link-item">Dashboard<!-- --></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">© 2025 UAV4GEO</div></div></div></footer></div>
</body>
</html>